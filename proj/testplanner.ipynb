{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhw/miniconda3/envs/robolearning/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "### setup code, don't change! ###\n",
    "import mani_skill.envs\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from mani_skill.utils.visualization import images_to_video\n",
    "from mani_skill.utils.wrappers.record import RecordEpisode\n",
    "import mplib\n",
    "from tqdm.notebook import tqdm\n",
    "from transforms3d.euler import euler2quat, quat2euler\n",
    "from test_env import TestTaskEnv\n",
    "\n",
    "env = gym.make(\"TestTask-v1\",\n",
    "                num_envs=1,\n",
    "                control_mode=\"pd_joint_pos\",\n",
    "                render_mode=\"rgb_array\",\n",
    "                reward_mode=\"none\",\n",
    "                human_render_camera_configs=dict(shader_pack=\"default\"),\n",
    "                obs_mode=\"state\"\n",
    "    )\n",
    "env = RecordEpisode(env, output_dir=\"drop_cube\", video_fps=20, info_on_video=True, save_trajectory=False)\n",
    "env.reset(seed=42)\n",
    "robot = env.unwrapped.agent.robot\n",
    "link_names = [link.get_name() for link in robot.get_links()]\n",
    "joint_names = [joint.get_name() for joint in robot.get_active_joints()]\n",
    "planner = mplib.Planner(\n",
    "    urdf=env.unwrapped.agent.urdf_path,\n",
    "    srdf=env.unwrapped.agent.urdf_path.replace(\".urdf\", \".srdf\"),\n",
    "    user_link_names=link_names,\n",
    "    user_joint_names=joint_names,\n",
    "    move_group=\"panda_hand_tcp\",\n",
    "    # ensures planned motions do not exceed these limits\n",
    "    joint_vel_limits=np.ones(7) * 0.8,\n",
    "    joint_acc_limits=np.ones(7) * 0.8,\n",
    ")\n",
    "# this sets the planner object up such that you can plan with poses in the world frame, which is the default frame of all pose data\n",
    "# in our simulator\n",
    "planner.set_base_pose(np.concatenate([robot.pose.sp.p, robot.pose.sp.q]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhw/miniconda3/envs/robolearning/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.get_info to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.get_info` for environment variables or `env.get_wrapper_attr('get_info')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'position'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m     83\u001b[0m     env\u001b[38;5;241m.\u001b[39mreset(seed\u001b[38;5;241m=\u001b[39mi)\n\u001b[0;32m---> 84\u001b[0m     \u001b[43mpick_cube_mp_solution\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     success \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mget_info()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     86\u001b[0m     successes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m success\n",
      "Cell \u001b[0;32mIn[2], line 57\u001b[0m, in \u001b[0;36mpick_cube_mp_solution\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# move to bin\u001b[39;00m\n\u001b[1;32m     50\u001b[0m grasp_result \u001b[38;5;241m=\u001b[39m planner\u001b[38;5;241m.\u001b[39mplan_screw(\n\u001b[1;32m     51\u001b[0m     np\u001b[38;5;241m.\u001b[39mconcatenate([goal_p \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,z_offset]), grasp_ori]),\n\u001b[1;32m     52\u001b[0m     robot\u001b[38;5;241m.\u001b[39mqpos\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     wrt_world\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     56\u001b[0m )\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pos \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgrasp_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mposition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     58\u001b[0m     env\u001b[38;5;241m.\u001b[39mstep(np\u001b[38;5;241m.\u001b[39mconcatenate([pos, [grasp]]))\n\u001b[1;32m     60\u001b[0m grasp_result \u001b[38;5;241m=\u001b[39m planner\u001b[38;5;241m.\u001b[39mplan_screw(\n\u001b[1;32m     61\u001b[0m     np\u001b[38;5;241m.\u001b[39mconcatenate([goal_p \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m,z_offset]), grasp_ori]),\n\u001b[1;32m     62\u001b[0m     robot\u001b[38;5;241m.\u001b[39mqpos\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m     wrt_world\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     66\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'position'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def pick_cube_mp_solution(env):\n",
    "    robot = env.unwrapped.agent.robot\n",
    "    panda_hand_tcp = env.unwrapped.agent.robot.links_map[\"panda_hand_tcp\"]\n",
    "    cube = env.unwrapped.cube\n",
    "    bin = env.unwrapped.bin\n",
    "    goal = env.unwrapped.goal_region\n",
    "   \n",
    "    ### Your code goes here ###\n",
    "    grasp_ori = panda_hand_tcp.pose.q[0].numpy().copy()\n",
    "    z_offset = 0.15\n",
    "    grasp = 1\n",
    "\n",
    "    # cube pose in world frame\n",
    "    cube_p = cube.pose.p[0].numpy().copy()\n",
    "    bin_p = bin.pose.p[0].numpy().copy()\n",
    "    goal_p = goal.pose.p[0].numpy().copy()\n",
    "    grasp_point = bin_p + np.array([0.08, 0.00, 0.0])\n",
    "   \n",
    "\n",
    "    planner.update_attached_sphere(\n",
    "        radius=1.0,\n",
    "        pose=np.concatenate([panda_hand_tcp.pose.p[0].numpy(), panda_hand_tcp.pose.q[0].numpy()]),\n",
    "        link_id=panda_hand_tcp.get_index()\n",
    "    )\n",
    "    \n",
    "    # grasp the cube\n",
    "    grasp_result = planner.plan_screw(\n",
    "        np.concatenate([grasp_point + np.array([0,0,z_offset]), grasp_ori]),\n",
    "        robot.qpos.cpu().numpy()[0],\n",
    "        time_step=env.unwrapped.control_timestep,\n",
    "        use_attach=True,\n",
    "        wrt_world=True\n",
    "    )\n",
    "    for pos in grasp_result[\"position\"]:\n",
    "        env.step(np.concatenate([pos, [grasp]]))\n",
    "\n",
    "    grasp_result = planner.plan_screw(\n",
    "        np.concatenate([grasp_point, grasp_ori]),\n",
    "        robot.qpos.cpu().numpy()[0],\n",
    "        time_step=env.unwrapped.control_timestep,\n",
    "        use_attach=True,\n",
    "        wrt_world=True\n",
    "    )\n",
    "    for i, pos in enumerate(grasp_result[\"position\"]):\n",
    "        if i == len(grasp_result[\"position\"]) - 1:\n",
    "            grasp = -1\n",
    "        env.step(np.concatenate([pos, [grasp]]))\n",
    "\n",
    "    # move to bin\n",
    "    grasp_result = planner.plan_screw(\n",
    "        np.concatenate([goal_p + np.array([0,0,z_offset]), grasp_ori]),\n",
    "        robot.qpos.cpu().numpy()[0],\n",
    "        time_step=env.unwrapped.control_timestep,\n",
    "        use_attach=True,\n",
    "        wrt_world=True\n",
    "    )\n",
    "    for pos in grasp_result[\"position\"]:\n",
    "        env.step(np.concatenate([pos, [grasp]]))\n",
    "\n",
    "    grasp_result = planner.plan_screw(\n",
    "        np.concatenate([goal_p + np.array([0,0,z_offset]), grasp_ori]),\n",
    "        robot.qpos.cpu().numpy()[0],\n",
    "        time_step=env.unwrapped.control_timestep,\n",
    "        use_attach=True,\n",
    "        wrt_world=True\n",
    "    )\n",
    "    for i, pos in enumerate(grasp_result[\"position\"]):\n",
    "        if i == len(grasp_result[\"position\"]) - 1:\n",
    "            grasp = 1\n",
    "        env.step(np.concatenate([pos, [grasp]]))\n",
    "    \n",
    "    # extra steps to see outcome\n",
    "    for _ in range(5):\n",
    "        env.step(np.concatenate([robot.qpos.cpu().numpy()[0][:7], [grasp]]))\n",
    "\n",
    "\n",
    "    ### your code goes above ###\n",
    "\n",
    "### evaluation code below ###\n",
    "EPISODES = 10\n",
    "successes = 0\n",
    "for i in range(10):\n",
    "    env.reset(seed=i)\n",
    "    pick_cube_mp_solution(env)\n",
    "    success = env.get_info()[\"success\"].item()\n",
    "    successes += success\n",
    "env.reset()\n",
    "print(f\"Success rate: {successes/EPISODES}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robolearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
